{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the *Optuna* framework\n",
    "\n",
    "*Optuna* is an automatic hyperparameter optimization software framework, designed for machine learning. It implements an imperative *define-by-run* API, meaning that the user of *Optuna* can dynamically construct the search spaces for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna library import\n",
    "import optuna\n",
    "\n",
    "# Additional imports\n",
    "import numpy\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import (figure, \n",
    "                            show)\n",
    "\n",
    "# Disable default logging on standard error\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "# Redirect Bokeh output to the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization 101: minimizing a quadratic function\n",
    "\n",
    "To get in touch with the *Optuna* framework, let's try to exploit the hyperparameters optimization engine for minimizing the simple, analytically defined, quadratic function *y = (x - 2)<sup>2</sup>*, which is minimized for *x = 2*\n",
    "\n",
    "*Optuna* is designed to optimize the outcome of a user-defined objective function, performing the number of iterations requested by the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to be minimized\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -20, 20)\n",
    "    \n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's clarify the terminology *Optuna* follows:\n",
    "- **Study**: An optimization session, i.e., a set of trials.\n",
    "- **Trial**: A single call of the objective function.\n",
    "- **Parameter**: A variable whose value is to be optimized, e.g., *x* in the above example.\n",
    "\n",
    "Our goal is to find out *x* that minimizes the output of the objective function. During the optimization, *Optuna* repeatedly invokes and evaluates the objective function with different values of *x*. The suggest APIs (e.g., `optuna.trial.Trial.suggest_uniform()`) are called inside `objective` to obtain parameters for a trial. To start the optimization, we create a study object and pass the objective function to method `optuna.study.Study.optimize()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective,\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! *Optuna* performed the requested number of trials trying to guess the proper value for the parameter to be optimized, looking at the output of the `objective` function.\n",
    "\n",
    "The `optuna.study.Study` class provides methods for inspecting the optimization outcome:\n",
    "- `optuna.study.Study.best_params` returns the best hyperparameter values discovered so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `optuna.study.Study.best_value` returns the value of the objective function computed with the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `optuna.study.Study.best_trial` reports exaustive information about the best trial done so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `optuna.study.Study.trials` reports exaustive information about all trials the study have done so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `optuna.study.Study.trials_dataframe()` provides the same information as `optuna.study.Study.trials` but exports them as a `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization process control\n",
    "\n",
    "The optimization procedure offers many handles for controlling its behaviour.\n",
    "\n",
    "### Controlling the amount of time for which the optimizer run \n",
    "\n",
    "As long as real-world hyperparameter procedures, especially those involving machine learning, may require a huge amount of time, `optuna.study.Study.optimize()` allows tuning the maximum time for which the optimization engine is allowed to run:\n",
    "- The `n_trials` parameter sets the maximum number of trials the study object can do.\n",
    "- The `timeout` parameter sets the maximum number of seconds for which the study can run.\n",
    "\n",
    "If both parameters are `None`, the optimizer continues running until the `SIGTERM` signal is received. In the following snippet, the optimizer is forced to stop after 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -20, 20)\n",
    "    \n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective,\n",
    "               timeout=1)\n",
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximizing objective functions\n",
    "\n",
    "Any `optuna.study.Study` object can be customized for solving both minimization and maximization problems, changing the value of the `direction` keyword argument whenever a new study is created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -20, 20)\n",
    "    \n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective,\n",
    "               timeout=1)\n",
    "print(f'Maximum value for x: {study.best_params[\"x\"]}')\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective,\n",
    "               timeout=1)\n",
    "print(f'Minimum value for x: {study.best_params[\"x\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameter spaces\n",
    "\n",
    "It is possible to choose five different settings for suggesting the optimizer the search space for each hyperparameter to be optimized:\n",
    "- `optuna.trials.Trial.suggest_categorical` for choosing the parameter among a list of categoricals.\n",
    "- `optuna.trials.Trial.suggest_int` for integer parameters within a range.\n",
    "- `optuna.trials.Trial.suggest_uniform` for real parameters within a range.\n",
    "- `optuna.trials.Trial.suggest_loguniform` for real parameters within a range, using a logarithmic scale.\n",
    "- `optuna.trials.Trial.suggest_discrete_uniform` for real parameters within a range with a fixed step.\n",
    "\n",
    "Let's try to run again the same quadratic function minimization, forcing the *x* parameter to be an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_real(trial):\n",
    "    x = trial.suggest_uniform('x', -20, 20)\n",
    "    \n",
    "    return (x - 2) ** 2\n",
    "\n",
    "def objective_int(trial):\n",
    "    x = trial.suggest_int('x', -20, 20)\n",
    "    \n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study_real = optuna.create_study()\n",
    "study_real.optimize(objective_real,\n",
    "                    n_trials=15)\n",
    "print(f'Best value for x: {study_real.best_params[\"x\"]}')\n",
    "study_int = optuna.create_study()\n",
    "study_int.optimize(objective_int,\n",
    "                   n_trials=15)\n",
    "print(f'Best value for x: {study_int.best_params[\"x\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: minimization of analytic functions\n",
    "\n",
    "Once the basic functionalities of the *Optuna* library are clear, it may be interesting to test the optimization engine on real-world problems. In the following section we will try to find the minimum of two analytical functions, often used as a benchmark for general-purpose optimization engine: the *Rosembrock*'s function and the *Branin RCOS* function. While the former has a single minimization point, the latter has three global minima meaning that it can be used as a test-case for checking the behaviour of *Optuna* in spaces where multiple points minimize the objective function.\n",
    "\n",
    "### Minimize the *Rosenbrock*'s function\n",
    "\n",
    "*Rosenbrock*â€™s banana function is continuous, differentiable, non separable, scalable and unimodal. It is famous for being commonly used as a test case for optimization software. It can be defined with an arbitrary number of input variables but for the sake of the following exercise we will use it in its 2-inputs form: \n",
    "$$f(x_0, x_1) = (1 - x_0)^2 + 100(x_1 - x_0^2)^2$$\n",
    "evaluated in the region such that\n",
    "$$x_0 \\in [-30,30], x_1 \\in [-30,30]$$\n",
    "where a single global minima is present in\n",
    "$$P(1, 1)$$ \n",
    "where \n",
    "$$f(P) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Rosembrock's function outcome\n",
    "def rosenbrock(x0, x1):\n",
    "    return (1 - x0) ** 2 + 100 * (x1 - x0 ** 2) ** 2\n",
    "\n",
    "# Define optimization cost function\n",
    "def objective(trial):\n",
    "    x0 = trial.suggest_uniform('x0', -30, 30)\n",
    "    x1 = trial.suggest_uniform('x1', -30, 30)\n",
    "    \n",
    "    return rosenbrock(x0, x1)\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective,\n",
    "               timeout=30)\n",
    "print(f'Trials performed : {len(study.trials)}')\n",
    "print(f'Best value       : {study.best_value}')\n",
    "print(f'Best parameters  : x0={study.best_params[\"x0\"]}, x1={study.best_params[\"x1\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the way *Optuna* guesses the trial parameters, plotting each trial point $P_t(x_0, x_1)$ in the seach space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure plot\n",
    "plot = figure(width=900,\n",
    "              height=450)\n",
    "plot.circle(x=[trial.params['x0'] \n",
    "               for trial in study.trials],\n",
    "            y=[trial.params['x1']\n",
    "               for trial in study.trials],\n",
    "            color='green',\n",
    "            line_color='black',\n",
    "            alpha=0.5,\n",
    "            size=6,\n",
    "            legend='Trials')\n",
    "plot.circle(x=[1],\n",
    "            y=[1],\n",
    "            color='red',\n",
    "            line_color='black',\n",
    "            size=10,\n",
    "            legend='Minimum')\n",
    "plot.xaxis.axis_label='x0'\n",
    "plot.yaxis.axis_label='x1'\n",
    "\n",
    "# Plot\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize the *Branin RCOS* function\n",
    "\n",
    "*Branin RCOS* function is a continuous, differentiable, non-deparable, non-scalable, multimodal function. It's analytical formulation is:\n",
    "$$f(x_0, x_1) = (x_1 - \\frac{5.1x_0^2}{4\\pi^2} + \\frac{5x_0}{\\pi} - 6)^2 + 10(1 - \\frac{1}{8\\pi})\\cos({x_0}) + 10$$\n",
    "evaluated in the region such that\n",
    "$$x_0 \\in [-5,10], x_1 \\in [0,15]$$\n",
    "where three global minima are present in\n",
    "$$P_0(-\\pi, 12.275), P_1(\\pi, 2.275), P_2(3\\pi, 2.425)$$ \n",
    "where \n",
    "$$f(P_0) = f(P_1) = f(P_2) = 0.3978873$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Rosembrock's function outcome\n",
    "def branin_rcos(x0, x1):\n",
    "    f0 = (x1 - 5.1 * (x0 ** 2) / (4 * numpy.pi ** 2) + 5 * x0 / numpy.pi - 6) ** 2\n",
    "    f1 = 10 * (1 - 1 / (8 * numpy.pi)) * numpy.cos(x0)\n",
    "    return f0 + f1 + 10\n",
    "\n",
    "# Define optimization cost function\n",
    "def objective(trial):\n",
    "    x0 = trial.suggest_uniform('x0', -5, 10)\n",
    "    x1 = trial.suggest_uniform('x1', 0, 15)\n",
    "    \n",
    "    return branin_rcos(x0, x1)\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective,\n",
    "               timeout=30)\n",
    "print(f'Trials performed : {len(study.trials)}')\n",
    "print(f'Best value       : {study.best_value}')\n",
    "print(f'Best parameters  : x0={study.best_params[\"x0\"]}, x1={study.best_params[\"x1\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's analyze the minimization process plotting each trial point $P_t(x_0, x_1)$ in the seach space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure plot\n",
    "plot = figure(width=900,\n",
    "              height=450,\n",
    "             x_range=(-6, 11),\n",
    "             y_range=(-1, 16))\n",
    "plot.circle(x=[trial.params['x0'] \n",
    "               for trial in study.trials],\n",
    "            y=[trial.params['x1']\n",
    "               for trial in study.trials],\n",
    "            color='green',\n",
    "            line_color='black',\n",
    "            alpha=0.5,\n",
    "            size=6,\n",
    "            legend='Trials')\n",
    "plot.circle(x=[-numpy.pi, numpy.pi, 3 * numpy.pi],\n",
    "            y=[12.275, 2.275, 2.425],\n",
    "            color='red',\n",
    "            line_color='black',\n",
    "            size=10,\n",
    "            legend='Minimum')\n",
    "plot.xaxis.axis_label='x0'\n",
    "plot.yaxis.axis_label='x1'\n",
    "\n",
    "# Plot\n",
    "show(plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
